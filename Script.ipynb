{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path = 'dataset/train_images.idx3-ubyte'\n",
    "train_label_path = 'dataset/train_labels.idx1-ubyte'\n",
    "test_image_path  = 'dataset/test_image.idx3-ubyte'\n",
    "test_label_path  = 'dataset/test_label.idx1-ubyte'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_process(path_file):\n",
    "    with open(path_file, 'rb') as file:\n",
    "        data = np.fromfile(file, np.uint8, offset=16)\n",
    "        data = data / 255\n",
    "        return data.reshape(-1, 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_process(path_file):\n",
    "    with open(path_file, 'rb') as file:\n",
    "        data = np.fromfile(file, np.uint8, offset=8)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = image_process(train_image_path)\n",
    "X_test  = image_process(test_image_path)\n",
    "y_train = label_process(train_label_path)\n",
    "y_test  = label_process(test_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape , y_train.shape , X_test.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "for i in range(10):\n",
    "    ax = plt.subplot(1,13,i+1)\n",
    "    ax.imshow(X_train[i] , cmap='gray')\n",
    "    plt.title('Label ' + str(y_train[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # validation set \n",
    "# random_indices = np.random.permutation(X_train.shape[0])\n",
    "# length_i = int(X_train.shape[0]*0.2)  # 20% pour la validation\n",
    "# val_indices = random_indices[: length_i]\n",
    "# train_indices = random_indices[length_i :]\n",
    "# X_val = X_train[val_indices]\n",
    "# X_train = X_train[train_indices]\n",
    "# y_val = y_train[val_indices]\n",
    "# y_train = y_train[train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape , y_train.shape , X_val.shape , y_val.shape "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modele 1 : K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNClassifier:\n",
    "    def euclideanDistance(self, x1, x2):\n",
    "        return np.sqrt(np.sum(np.square(x1 - x2))) \n",
    "    \n",
    "    def manhattanDistance(self, x1, x2):\n",
    "        return np.sum(np.abs(x1 - x2))\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "    \n",
    "    def predect(self, k, X_test, distance='euclidean', weights='uniform'):\n",
    "        y_pred = []\n",
    "        \n",
    "        for x in X_test:\n",
    "            if distance == 'manhattan':\n",
    "                distances = [self.manhattanDistance(x, x_train) for x_train in self.X_train]\n",
    "            else:\n",
    "                distances = [self.euclideanDistance(x, x_train) for x_train in self.X_train]\n",
    "                     \n",
    "            k_indices = np.argsort(distances)[:k]\n",
    "            k_labels = self.y_train[k_indices]\n",
    "            \n",
    "            if weights == 'distance':\n",
    "                y = k_labels[np.argmax(np.bincount(k_labels) * (1 / distances[k_indices]))]\n",
    "                y_pred.append(y)\n",
    "            else:\n",
    "                y = np.argmax(np.bincount(k_labels))\n",
    "                y_pred.append(y)\n",
    "        \n",
    "        return np.array(y_pred)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETRES \n",
    "k = 4\n",
    "distance_type = 'manhattan'\n",
    "weight_type = 'uniform'\n",
    "\n",
    "# prend en petit partie du data\n",
    "\n",
    "xpetit_train = X_train[ : 500]\n",
    "ypetit_train = y_train[ : 500]\n",
    "\n",
    "xpetit_test = X_test[ : 10]\n",
    "ypetit_test = y_test[ : 10]\n",
    "\n",
    "xpetit_train = np.reshape(xpetit_train, (xpetit_train.shape[0], -1))\n",
    "train = np.reshape(ypetit_train, (ypetit_train.shape[0], -1))\n",
    "xpetit_test = np.reshape(xpetit_test, (xpetit_test.shape[0], -1))\n",
    "ypetit_test = np.reshape(ypetit_test, (ypetit_test.shape[0], -1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNNClassifier()\n",
    "\n",
    "model.fit(xpetit_train , ypetit_train)\n",
    "\n",
    "ypred = model.predect( k , xpetit_test, distance=distance_type, weights=weight_type)\n",
    "\n",
    "accuracy = accuracy_score(ypetit_test, ypred)\n",
    "print(\"Accuracy : {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "model.fit(xpetit_train, ypetit_train)\n",
    "\n",
    "y_pred = model.predict(xpetit_test)\n",
    "\n",
    "accuracy = accuracy_score(ypetit_test, y_pred)\n",
    "print(\"Accuracy : {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 : Logistique regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogistiqueClssifieur:\n",
    "    \n",
    "    def __init__(self, alpha, iterations, normalize = True):\n",
    "        self.alpha = alpha\n",
    "        self.iterations = iterations    \n",
    "        self.normalize = normalize    \n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        # recuperer nombre du classe \n",
    "        self.classes = np.unique(y_train)\n",
    "        self.nombre_classes = len(self.classes)\n",
    "        \n",
    "        # pour ajouter 1 \n",
    "        intercept = np.ones((X_train.shape[0], 1))\n",
    "        self.X_train = X_train.reshape(X_train.shape[0] , -1)\n",
    "        \n",
    "        # faire normalisation\n",
    "        if self.normalize :\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit( self.X_train)\n",
    "            self.X_train = np.column_stack((intercept, scaler.transform(self.X_train)))\n",
    "        else : self.X_train = np.column_stack((intercept, X_train))\n",
    "        \n",
    "        self.y_train = y_train.reshape(y_train.shape[0] , 1)  \n",
    "        #initilaiser les thetas      \n",
    "        self.theta = np.zeros((self.nombre_classes , self.X_train.shape[1]))\n",
    "        # mise a jour les theta \n",
    "        self.predictMultiClasses()\n",
    "            \n",
    "    def derivative(self, theta , y):       \n",
    "        m = len(self.X_train)\n",
    "        h_theta = self.sigmoid(self.X_train @ theta.T)\n",
    "        return (self.X_train.T @ (h_theta - y)).T / m    \n",
    "    \n",
    "    def computeCostLogistique(self, theta , y):\n",
    "        m = len(self.X_train)\n",
    "        h_theta = self.sigmoid(self.X_train @ theta.T )        \n",
    "        h_theta[h_theta == 0.] += np.finfo(float).eps\n",
    "        h_theta[h_theta == 1.] -= np.finfo(float).eps  \n",
    "        return - np.sum( y.T @ np.log(h_theta) + (1 - y).T @ np.log(1 - h_theta))  / m\n",
    "\n",
    "    def gradientDescent(self , y):\n",
    "        theta_optimum = np.zeros((1 , self.X_train.shape[1]))\n",
    "        theta = np.zeros((1 , self.X_train.shape[1]))\n",
    "        cost_optimum = self.computeCostLogistique(theta,y)\n",
    "        for i in range(self.iterations):\n",
    "            delta_theta = self.derivative(theta , y)            \n",
    "            theta = theta - self.alpha * delta_theta         \n",
    "            cost = self.computeCostLogistique(theta, y)\n",
    "            if cost_optimum > cost:\n",
    "                theta_optimum = np.array(theta)\n",
    "                cost_optimum = cost\n",
    "        return theta_optimum\n",
    "    \n",
    "    def predictMultiClasses(self ):                \n",
    "        for i in range(self.nombre_classes):            \n",
    "            theta = self.gradientDescent( ( self.y_train == self.classes[i] ).astype(int))\n",
    "            self.theta[i, :] = theta       \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        intercept = np.ones((X_test.shape[0], 1))\n",
    "        X_test = X_test.reshape(X_test.shape[0] , -1)\n",
    "        if self.normalize :\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(X_test)\n",
    "            X_test = np.column_stack((intercept, scaler.transform(X_test)))\n",
    "        else :  X_test = np.column_stack((intercept, X_test) ) \n",
    "        proba = X_test @ self.theta.T\n",
    "        max_proba_classe = np.argmax(proba , axis=1)\n",
    "        predect = self.classes[ max_proba_classe]\n",
    "        return predect.reshape((-1, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = LogistiqueClssifieur(0.01 , 1000 , False)\n",
    "#model.fit(xpetit_train, ypetit_train)\n",
    "# save modele \n",
    "filename = 'LogistiqueClassifieurModel.sav'\n",
    "#joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open model\n",
    "model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model.predict(xpetit_test)\n",
    "ypetit_test = ypetit_test.reshape(xpetit_test.shape[0] , 1)\n",
    "accuracy = accuracy_score(ypetit_test, ypred)\n",
    "print(\"Accuracy : {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 : RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self , hidden_layer_sizes, alpha, iterations , normalize = True) :\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.alpha = alpha\n",
    "        self.iterations = iterations\n",
    "        self.normalize = normalize\n",
    "        \n",
    "    def initialization_weights(self):\n",
    "        low = - 0.1\n",
    "        high = 0.1 \n",
    "        self.weights = []\n",
    "        self.baiais  = []       \n",
    "        # Layer 1  \n",
    "        w = np.random.uniform(low, high, size = (self.hidden_layer_sizes[0], self.input_layer_size ))\n",
    "        self.weights.append(w)\n",
    "        b = np.random.uniform(low, high, size = (w.shape[0] , 1))  \n",
    "        self.baiais.append(b)   \n",
    "                \n",
    "        for i in range((len(self.hidden_layer_sizes)) - 1 ) :\n",
    "            w = np.random.uniform(low, high, size = (self.hidden_layer_sizes[i+1], self.hidden_layer_sizes[i]))\n",
    "            self.weights.append(w)\n",
    "            b = np.random.uniform(low, high, (w.shape[0] , 1))  \n",
    "            self.baiais.append(b)   \n",
    "             \n",
    "        #  outout layer\n",
    "        w = np.random.uniform(low, high, size = ( self.output_layer_size , self.hidden_layer_sizes[-1]) )\n",
    "        b = np.random.uniform(low, high, (w.shape[0] , 1))   \n",
    "        self.baiais.append(b)    \n",
    "        self.weights.append(w)         \n",
    "        return self.weights , self.baiais\n",
    "    \n",
    "    def sigmoid(z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def activation( z):\n",
    "        return RNN.sigmoid(z)\n",
    "    \n",
    "    def lossFunction(self, weights, baiais):\n",
    "        m = self.y_train.shape[0]        \n",
    "        a = RNN.forwardPropagation(self.X_train , weights, baiais)\n",
    "        return - np.sum(  self.YY @ np.log(a[-1]) +  ( 1 - self.YY ) @ np.log( 1 - a[-1] ) ) / m \n",
    "     \n",
    "    def forwardPropagation(X, weights, baiais):\n",
    "        a_all_layer = []\n",
    "        a = np.transpose(X)\n",
    "        a_all_layer.append(a)\n",
    "        \n",
    "        for i in range(len(weights)): \n",
    "            z = weights[i] @ a + baiais[i]\n",
    "            a = RNN.activation(z)   \n",
    "            a_all_layer.append(a)\n",
    "            \n",
    "        return a_all_layer\n",
    "            \n",
    "    def backPropagation(self):\n",
    "        weights , baises = self.initialization_weights()\n",
    "        cost_optimum = self.lossFunction(weights , baises)\n",
    "                \n",
    "        for i in range(self.iterations):\n",
    "            a = RNN.forwardPropagation(self.X_train , weights , baises)  # 4 ACTIVATIONS\n",
    "\n",
    "            dalta_weights = []\n",
    "            dalta_baises = []\n",
    "            \n",
    "            # dz output layer\n",
    "            dz = a[-1] - self.YY.T    # 10 * 500 \n",
    "            dw = dz @ a[-2].T ###########################################\n",
    "\n",
    "            dalta_weights.append(dw)\n",
    "            dalta_baises.append(dz) # db = dz\n",
    "            \n",
    "            for L  in range( len(self.hidden_layer_sizes) - 1 , -1 , -1  ):             \n",
    "                dz = weights[ L + 1].T @ dz * a[L + 1] * ( 1 - a[L + 1])\n",
    "                \n",
    "                dw = dz @ a[L].T ##################\n",
    "                \n",
    "                dalta_weights = [ dw ] + dalta_weights\n",
    "                dalta_baises = [ dz ] + dalta_baises            \n",
    "            \n",
    "            \n",
    "            mean_dalta_weights = [np.mean(dalta_weight , axis = 0).reshape((-1,1)) for dalta_weight in dalta_weights]\n",
    "            mean_dalta_baises = [np.mean(dalta_baises , axis = 1).reshape((-1,1))  for dalta_baises in dalta_baises]\n",
    "            \n",
    "            for k in range(len(weights)):\n",
    "               \n",
    "                weights[k] = weights[k] - self.alpha * mean_dalta_weights[k].T\n",
    "                baises[k] = baises[k] - self.alpha * mean_dalta_baises[k]  \n",
    "\n",
    "            cost = self.lossFunction(weights, baises)\n",
    "            if cost < cost_optimum : \n",
    "                cost_optimum = cost\n",
    "                self.weights = weights\n",
    "                self.baiais = baises   \n",
    "        print(cost_optimum)\n",
    "        return self.weights , self.baiais\n",
    "        \n",
    "    def fit(self, X_train , y_train):\n",
    "        # recuperer nombre du classe \n",
    "        self.classes = np.unique(y_train)\n",
    "        self.nombre_classes = len(self.classes)\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "        self.YY = np.zeros((y_train.shape[0] , self.nombre_classes ))\n",
    "        \n",
    "        for i in range(self.nombre_classes):\n",
    "            self.YY[ : , i ] = ( self.y_train == self.classes[i] ).astype(int)\n",
    "            \n",
    "        # faire normalisation\n",
    "        if self.normalize :\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit( self.X_train)\n",
    "            self.X_train = scaler.transform(self.X_train)\n",
    "\n",
    "        self.input_layer_size =  X_train.shape[1]\n",
    "        self.output_layer_size = self.nombre_classes\n",
    "        \n",
    "        self.backPropagation()\n",
    "        \n",
    "        return -1\n",
    "        \n",
    "    def predict(self, X_test ):       \n",
    "        proba = RNN.forwardPropagation(X_test , self.weights, self.baiais)[-1]\n",
    "        max_proba_classe = np.argmax(proba , axis=0)\n",
    "        predect = self.classes[ max_proba_classe]\n",
    "        return predect.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN( (15 , ) , 0.01 , 1000)\n",
    "model.fit(xpetit_train , ypetit_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model.predict(xpetit_test)\n",
    "accuracy = accuracy_score(ypetit_test, ypred)\n",
    "print(\"Accuracy : {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    def __init__(self , hidden_layer):\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self._fix_parameters()   \n",
    "        self.activation = NeuralNet.sigmoid    \n",
    "    \n",
    "    def _fix_parameters(self , lr = 0.01 , epoches = 1000 , normalize = True):\n",
    "        self.lr = lr \n",
    "        self.epoches = epoches \n",
    "        self.normalize = normalize \n",
    "        \n",
    "    def sigmoid(z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def forward(self , X, weights , baias):        \n",
    "        a_all_layer = []\n",
    "        a = X.T     \n",
    "        a_all_layer.append(a)   \n",
    "        for i in range(len(weights)):\n",
    "            z = weights[i] @ a + baias[i]\n",
    "            a = self.activation(z)\n",
    "            a_all_layer.append(a)            \n",
    "        return a_all_layer\n",
    "       \n",
    "    def lossFunction(self , X   , YY , weights , baias):\n",
    "        ypred = self.forward(X , weights , baias) [-1]\n",
    "        return np.mean(YY @ np.log(ypred) )\n",
    "         \n",
    "       \n",
    "    def initialization_weights(self):\n",
    "        self.weights = []\n",
    "        self.baias = [] \n",
    "        \n",
    "        low = - 0.1\n",
    "        high = 0.1\n",
    "        \n",
    "        # input layer \n",
    "        w = np.random.uniform(low, high, size = (self.hidden_layer[0], self.input_layer_size ))\n",
    "        self.weights.append(w)\n",
    "        b = np.random.uniform(low, high, size = (w.shape[0] , 1))  \n",
    "        self.baias.append(b)   \n",
    "                \n",
    "        for i in range((len(self.hidden_layer)) - 1 ) :\n",
    "            w = np.random.uniform(low, high, size = (self.hidden_layer[i+1], self.hidden_layer[i]))\n",
    "            self.weights.append(w)\n",
    "            b = np.random.uniform(low, high, (w.shape[0] , 1))  \n",
    "            self.baias.append(b)   \n",
    "             \n",
    "        #  outout layer\n",
    "        w = np.random.uniform(low, high, size = ( self.output_layer_size , self.hidden_layer[-1]) )\n",
    "        b = np.random.uniform(low, high, (w.shape[0] , 1))   \n",
    "        self.baias.append(b)    \n",
    "        self.weights.append(w)   \n",
    "              \n",
    "        return self.weights , self.baias\n",
    "    \n",
    "    def backward(self , a_all , weights ):\n",
    "        \n",
    "        dalta_weights = []\n",
    "        dalta_baises = []\n",
    "            \n",
    "        # dz output layer\n",
    "        dz = a_all[-1] - self.YY.T    # 10 * 500 \n",
    "        dw = dz @ a_all[-2].T ###########################################\n",
    "\n",
    "        dalta_weights.append(dw)\n",
    "        dalta_baises.append(dz) # db = dz\n",
    "            \n",
    "        for L  in range( len(self.hidden_layer) - 1 , -1 , -1  ):             \n",
    "            dz = weights[ L + 1].T @ dz * a_all[L + 1] * ( 1 - a_all[L + 1])\n",
    "                \n",
    "            dw = dz @ a_all[L].T ##################\n",
    "              \n",
    "            dalta_weights = [ dw ] + dalta_weights\n",
    "            dalta_baises = [ dz ] + dalta_baises            \n",
    "            \n",
    "            \n",
    "            mean_dalta_weights = [np.mean(dalta_weight , axis = 0).reshape((-1,1)) for dalta_weight in dalta_weights]\n",
    "            mean_dalta_baises = [np.mean(dalta_baises , axis = 1).reshape((-1,1))  for dalta_baises in dalta_baises] \n",
    "            \n",
    "        return mean_dalta_weights , mean_dalta_baises\n",
    "               \n",
    "        \n",
    "    def fit(self, X_train , y_train):\n",
    "        \n",
    "        self.classes = np.unique(y_train)\n",
    "        self.nombre_classes = len(self.classes)\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "       \n",
    "            \n",
    "            \n",
    "        # faire normalisation\n",
    "        if self.normalize :\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit( self.X_train)\n",
    "            self.X_train = scaler.transform(self.X_train)\n",
    "\n",
    "        self.input_layer_size =  X_train.shape[1]\n",
    "        self.output_layer_size = self.nombre_classes\n",
    "        \n",
    "        weights , baias = self.initialization_weights()\n",
    "        loss_optim = self.lossFunction(self.X_train , self.YY , self.weights , self.baias)\n",
    "        \n",
    "        for epoch in range(self.epoches):\n",
    "            \n",
    "            a = self.forward(self.X_train , weights , baias)\n",
    "        \n",
    "            dw , db  = self.backward( a , weights)\n",
    "\n",
    "            \n",
    "            for i in range(len(weights)):\n",
    "               \n",
    "                weights[i] = weights[i] - self.lr * dw[i].T\n",
    "                baias[i] = baias[i] - self.lr * db[i]  \n",
    "\n",
    "            loss = self.lossFunction(self.X_train , self.YY , weights, baias)\n",
    "            if loss < loss_optim : \n",
    "                loss_optim = loss\n",
    "                self.weights = weights\n",
    "                self.baiais = baias   \n",
    "                \n",
    "        print(loss_optim)\n",
    "        \n",
    "        return self.weights , self.baias\n",
    "    \n",
    "    def predict(self, X_test ):       \n",
    "        proba = RNN.forwardPropagation(X_test , self.weights, self.baiais)[-1]\n",
    "        print(proba)\n",
    "        max_proba_classe = np.argmax(proba , axis=0)\n",
    "        predect = self.classes[ max_proba_classe]\n",
    "        return predect.reshape((-1, 1))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet((15 ,))\n",
    "model.fit(xpetit_train , ypetit_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model.predict(xpetit_train)\n",
    "accuracy = accuracy_score(ypetit_train, ypred)\n",
    "print(\"Accuracy : {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07224444086086405"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = np.random.uniform( -0.1 , 0.1 , size = ( 15 , 784))\n",
    "b1 = np.random.uniform( -0.1, 0.1 , size=(15 , 1))\n",
    "w2 = np.random.uniform( -0.1 , 0.1 , size = ( 10 , 15))\n",
    "b2 = np.random.uniform( -0.1, 0.1 , size=(10 , 1))\n",
    "\n",
    "def forward(X):\n",
    "    a1 = sigmoid(w1 @ X.T)\n",
    "    a2 = sigmoid(w2 @ a1 )\n",
    "    return a1 , a2 \n",
    "\n",
    "def backward(X , a1 , a2):\n",
    "   \n",
    "   dz2 = a2 - YY.T # (10 * 500)\n",
    "   dw2 = dz2 @ a1.T    # 10 * 500 @ 500 * 15   =  10 * 15           \n",
    "   db2 = dz2       # 10 * 500\n",
    "   \n",
    "   dz1 = w2.T @ dz2 * a1 * ( 1 - a1 )   \n",
    "   dw1 = dz1 @ X\n",
    "   db2 = dz1 \n",
    "                \n",
    "   db2 = np.mean(db2 , axis = 1)\n",
    "   db1 = np.mean(db1 , adix = 1)\n",
    "   \n",
    "   print(db1.shape , db2.shape)\n",
    "   \n",
    "    \n",
    "   return dw1 , db1 , dw2 , db2 \n",
    "               \n",
    "        \n",
    "\n",
    "def lossFunction(X , YY):\n",
    "    _, ypred = forward(X)\n",
    "    ypred = ypred.T\n",
    "    return - np.mean( YY * np.log(ypred))\n",
    "    \n",
    "YY = np.zeros(( ypetit_train.shape[0] , 10 )   )  \n",
    "for i in range(10):\n",
    "    YY[ : , i ] = ( ypetit_train == i ).astype(int)\n",
    "    \n",
    "    \n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimale = ( w1 , b1 , w2 , b2)\n",
    "lossOptim = lossFunction(xpetit_train)\n",
    "\n",
    "def gradinetDescent(X):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        a1 , a2 = forward(xpetit_train)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 500)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 , a2 = forward(xpetit_train)\n",
    "a2.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
